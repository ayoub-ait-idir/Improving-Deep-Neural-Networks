# Improving-Deep-Neural-Networks
In this notebook, I learnt how to improve my Deep Neural Networks' performance, by applying different optimization methods in addition to the classic gradient Descent, I tried Stochastic Gradiant Descent (SGD), Momentum and Adam methods an saw the result found with each one.
